\documentclass[11pt]{article}

\usepackage{amsfonts}

\usepackage{fancyhdr}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{amsrefs}
\usepackage{ulem}
\usepackage[dvips]{graphicx}
\usepackage{bm}
\usepackage{cancel}
\usepackage{color}
\usepackage{bm}

\setlength{\headheight}{26pt}
\setlength{\oddsidemargin}{0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8.5in}

\topmargin 0pt
%Forrest Shortcuts
\newtheorem{defn}{Definition}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{pf}{Proof}
\newtheorem{sol}{Solution}
\newcommand{\R}{{\ensuremath{\mathbb R}}}
\newcommand{\J}{{\ensuremath{\mathbb J}}}
\newcommand{\Z}{{\mathbb Z}}
\newcommand{\N}{{\mathbb N}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\st}{{\text{\ s.t.\ }}}
\newcommand{\rto}{\hookrightarrow}
\newcommand{\rtto}{\hookrightarrow\rightarrow}
\newcommand{\tto}{\to\to}
\newcommand{\C}{{\mathbb C}}
\newcommand{\ep}{\epsilon}
%CJ shortcuts
\newcommand{\thin}{\thinspace}
\newcommand{\beps}{\boldsymbol{\epsilon}}
\newcommand{\bwoc}{by way of contradiction}

%Munkres formatting?
%\renewcommand{\theenumii}{\alph{enumi}}
\renewcommand{\labelenumi}{\theenumi.}
\renewcommand{\theenumii}{\alph{enumii}}
\renewcommand{\labelenumii}{(\theenumii)}

\title{Final}
\author{Guanlin Zhang}

\lhead{Dr Milind Phadnis
 \\BIOS 900} \chead{}
\rhead{Guanlin Zhang\\Fall '17} \pagestyle{fancyplain}
%\maketitle

\begin{document}
Question $\# 1$.
\begin{sol}
	For part $(a)$:\vskip 2mm
	The model here is in the formof :
	\begin{align*}
		{\bf y} = {\bf X}{\bm \beta} + {\bm \epsilon}
	\end{align*}
	where
	\begin{align*}
		{\bf X} &= \left[\begin{array}{cc} X_{11}& X_{21}\\ X_{12}& X_{22}\\ X_{13} &X_{23}\\ X_{14}&X_{24}\end{array}\right] \hskip 1cm {\bm \beta} = \left[\begin{array}{c}\beta_1\\ \beta_2 \end{array}\right] \hskip 1cm {\bm \epsilon} = \left[\begin{array}{c} \epsilon_1\\ \epsilon_2 \\ \epsilon_3 \\ \epsilon_4\end{array}\right]
	\end{align*}
	and $E[\epsilon_i] = 0$ for $i = 1, 2, 3, 4$.\vskip 2mm
	To make this a normal theory Gauss Markov model, or in other words, to make the ordinary least square estimate become the best linear unbiased estimator(BLUE), we need to impose the following assumptions:
	\begin{align*}
		{\bm \epsilon} \sim N({\bf 0}, \sigma^2{\bf I})
	\end{align*}
	which implies normal, independence and equal variance.
	\vskip 2mm
	For part $(b)$:\vskip 2mm
	If conditioned on $X_{1i} = X_{1j}$ for $i \neq j$, assume $X_{2i} = 1$ and $X_{2j} = -1$, then we have:
	\begin{align*}
		E[y_{i}] &= \beta_1X_{1i}+\beta_2\\
		E[y_{j}] &= \beta_1X_{1j} -\beta_2
	\end{align*}
	So
	\begin{align*}
		&\ E[y_{i}] - E[y_{j}] = 2\beta_2 \Longrightarrow \beta_2 = \frac{1}{2}\Big(E[y_i] - E[y_j]\Big)
	\end{align*}
	So $\beta_2$ means on average half amount of difference in escaped vapor between using or not using the devie, while conditioned on the same temperature.\vskip 2mm
	For part $(c)$:\vskip 2mm
	If the condition in part $(a)$ is satisfied, then our model is a Gauss-Markov model, so ${\bf b}$ is the best linear unbiased estimator of ${\bm \beta}$(BLUE), or in other words, ${\bf b}$ has the minimum variance among all linear estimators of ${\bm \beta}$ that are unbiased.\vskip 2mm
	For part $(d)$:\vskip 2mm
	We have:
	\begin{align*}
		{\bf c}^T{\bf y} = (y_3 + y_4 - y_1 - y_2) \sim N({\bf c}^T{\bf X}{\bm \beta}, \sigma^2{\bf c}^T{\bf c})
	\end{align*}
	with 
	\begin{align*}
		{\bf c}^T{\bf X}{\bf \beta} &= (-1, -1, 1, 1) \left[\begin{array}{cc} X_{11}& X_{21}\\ X_{12}& X_{22}\\ X_{13} &X_{23}\\ X_{14}&X_{24}\end{array}\right] \left[\begin{array}{c}\beta_1\\ \beta_2 \end{array}\right]\\
		&= (-1, -1, 1, 1) \left[\begin{array}{cc} 0& -1\\ 30& -1\\ 0 &1\\ 30&1\end{array}\right] \left[\begin{array}{c}\beta_1\\ \beta_2 \end{array}\right]\\
		&= [0, 4]\left[\begin{array}{c}\beta_1\\ \beta_2 \end{array}\right]\\
		&= 4\beta_2
	\end{align*}
	and 
	\begin{align*}
		{\bf c}^T{\bf c} &= 4
	\end{align*}
	So we have:
	\begin{align*}
		\hat{\beta}_2= \frac{1}{4}(Y_3 + Y_4 - Y_1 - Y_2)
	\end{align*}
	Meanwhile the estimates for $\sigma^2$ is:
	\begin{align*}
		\hat{\sigma}^2 &= \frac{MSE}{\sum (X_{2i} - \overline{X}_2)^2} = \frac{SSE/(4-2)}{\sum (X_{2i} - 0)^2} = \frac{SSE/2}{4} = \frac{SSE}{8}
	\end{align*}
	So we have
	\begin{align*}
		\frac{\hat{\beta}_2 -0}{\hat{\sigma}} = \frac{ \frac{1}{4}(Y_3 + Y_4 - Y_1 - Y_2)}{\sqrt{SSE/8}} = \frac{Y_3 + Y_4 - Y_1 - Y_2}{\sqrt{2\ast SSE}}\sim t(2)
	\end{align*}
	under the null hypothesis
	\begin{align*}
		H_0: \beta_2 = 0
	\end{align*}
	which implies
	\begin{align*}
		\frac{(\hat{\beta}_2 - 0)^2}{\hat{\sigma}^2} = \frac{(Y_3 + Y_4 - Y_1 - Y_2)^2}{2\ast SSE} \sim F(1, 2)
	\end{align*}
	so the numerator degree of freedom is $1$, denominator degree of freedom is $2$.\vskip 2mm
	For part $(e)$:\vskip 2mm
	Given the $F$ test in part $(d)$, we have:
	\begin{align*}
		H_0: \beta_2 = 0 \text{ versus } H_1: \beta_2 \neq 0
	\end{align*}
	For part $(f)$:\vskip 2mm
	Suppose we add te interaction effect, then our model becomes
	\begin{align*}
		Y_i = \beta_1(X_{1i}) + \beta_2(X_{2i}) + \beta_3(X_{1i}\cdot X_{2i}) + \epsilon_i
	\end{align*}
	then our design matrix becomes
	\begin{align*}
		{\bf X} = \left[\begin{array}{ccc} 0&-1&0\\ 30&-1&-30\\ 0&1&0\\ 30&1 & 30\end{array}\right]
	\end{align*}
	we can see that the rank of ${\bf X}$ is $3$ since apparently the $3$ columns of ${\bf X}$ are linearly independent. Since the design matrix is still full rank, so we can get an estimate for $\beta_3$ which is the coefficient for interaction.\vskip 2mm
	Our initial SSE has degree of freedom of $4 - 2 = 2$, so if we add the interaction term, it can still afford to lose one more degree of freedom.
\end{sol}

Question $2$.
\begin{sol}
	For part $(a)$:\vskip 2mm
	The ``unconstrained'' cell means model is given as :
	\begin{align*}
		y_{ijk} = \mu_{ij} + \epsilon_{ijk}
	\end{align*}
	in our case we have $i = 1, 2, 3$ representing the level of cement and $j = 1, 2, 3, 4$ representing the level of aggregate.\vskip 2mm
	If we write the model in the matrix form it is:
	\begin{align*}
		{\bf y} &= {\bf W}{\bm \mu} + {\bm \epsilon}
	\end{align*}
	where ${\bf y}$ is a column vector of length $12$ and ${\bf W}$ is the design matrix with dimension $33 \times 12$ (we have $N = 33$ cell counts).\vskip 2mm
	\begin{center}
		\includegraphics[width = 14cm]{q201.jpg}
	\end{center}
	The $W$ design matrix looks like this:
	\begin{center}
		\includegraphics[width = 14cm]{q202.jpg}
	\end{center}
	
	We can find
	\begin{align*}
		s^2 &= \frac{SSE}{v_E} = \frac{({\bf y} - {\bf W}\hat{{\bm \mu}})'({\bf y} - {\bf W}\hat{{\bm \mu}})}{N - ab} = \frac{({\bf y} - {\bf W}\hat{{\bm \mu}})'({\bf y} - {\bf W}\hat{{\bm \mu}})}{33 - 12} 
	\end{align*}
	To test main effect of cement (factor A), our null hypothesis is:
	\begin{align*}
		H_0: \left \{\begin{array}{l}2(\mu_{11} + \mu_{12} + \mu_{13} + \mu_{14}) = (\mu_{21} + \mu_{22} + \mu_{23} + \mu_{24}) + (\mu_{31} + \mu_{32} + \mu_{33} + \mu_{34}) \\ \mu_{21} + \mu_{22} + \mu_{23} + \mu_{24} = \mu_{31} + \mu_{32} + \mu_{33} + \mu_{34} \end{array}\right.
	\end{align*}
	This is equivalent to the following generalized linear hypothesis:
	\begin{align*}
		H_0: {\bf A}{\bm\mu} = 0
	\end{align*}
	with ${\bm\mu} = (\mu_{11}, \mu_{12}, \mu_{13}, \mu_{14}, \mu_{21}, \mu_{22}, \mu_{23}, \mu_{24}, \mu_{31}, \mu_{32}, \mu_{33}, \mu_{34})' $ and
	\begin{align*}
		{\bf A} &= \left(\begin{array}{cccccccccccc} 2&2&2&2&-1&-1&-1&-1&-1&-1&-1&-1\\ 0 &0&0&0&1&1&1&1&-1&-1&-1&-1\end{array}\right)
	\end{align*}
	Our test statistic is:
	\begin{align*}
		F &= \frac{SSA/v_{A}}{SSE/v_E}= \frac{({\bf A}\hat{{\bm\mu}})'[{\bf A}({\bf W}'{\bf W})^{-1}{\bf A}']^{-1}{\bf A}\hat{{\bm\mu}}/v_{A}}{SSE/v_E}
	\end{align*}
	with 
	\begin{align*}
		\hat{{\bm\mu}} &= ({\bf W}'{\bf W})^{-1}{\bf W}'{\bf y}\\
		v_{A} &= (a - 1) = 2 \\
		v_{E} &= N - ab = 33 - 12 = 21
	\end{align*}
	We have SAS code as following:
	\begin{center}
		\includegraphics[width = 12cm]{q203.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 12cm]{q204.jpg}
	\end{center}
	Continue with the test, we give output for $F$ statistics, $SSA$ value and p value:
	\begin{center}
		\includegraphics[width = 12cm]{q205.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 12cm]{q206.jpg}
	\end{center}
	the p value is significant $(0.0015)$ so we reject $H_0$ and conclude that there is a different main effect between different types of cement.\vskip 2mm
	Similarly we have the null hypothesis for testing the main effect of aggregate (factor B) as:
	\begin{align*}
		H_0: \left\{\begin{array}{l} 3(\mu_{11} + \mu_{21} + \mu_{31}) = (\mu_{12} + \mu_{22} + \mu_{32}) + (\mu_{13} + \mu_{23} + \mu_{33}) + (\mu_{14} + \mu_{24} + \mu_{34})\\ 2(\mu_{12} + \mu_{22} + \mu_{32}) = (\mu_{13} + \mu_{23} + \mu_{33}) + (\mu_{14} + \mu_{24} + \mu_{34})\\ \mu_{13} + \mu_{23} + \mu_{33} = \mu_{14} + \mu_{24} + \mu_{34}\end{array}\right.
	\end{align*}
	which is equivalent to the general linear hypothesis:
	\begin{align*}
		H_0: {\bf B}{\bm \mu}= 0
	\end{align*}
	with
	\begin{align*}
		B &= \left(\begin{array}{cccccccccccc} 3&-1&-1&-1&3&-1&-1&-1&3&-1&-1&-1\\ 0 &2&-1&-1&0&2&-1&-1&0&2&-1&-1\\ 0&0&1&-1&0&0&1&-1&0&0&1&-1\end{array}\right)
	\end{align*}
	Our test statistic is:
	\begin{align*}
		F &= \frac{SSB/v_{B}}{SSE/v_E}= \frac{({\bf B}\hat{{\bm\mu}})'[{\bf B}({\bf W}'{\bf W})^{-1}{\bf B}']^{-1}{\bf B}\hat{{\bm\mu}}/v_{B}}{SSE/v_E}
	\end{align*}
	with 
	\begin{align*}
		v_{B} &= (b - 1) = 3
	\end{align*}
	Corresponding SAS code and output:
	\begin{center}
		\includegraphics[width = 12cm]{q207.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 10cm]{q208.jpg}
	\end{center}
	the p value is highly sigificant so we reject the null hypothesis and conclude there is a main effect difference from different types of aggregate.\vskip 2mm
	Finally we can use hadamad product from $A$ and $B$ to get the orthogonal contrast matrix for testing interaction. We have
	\begin{align*}
		C = \left(\begin{array}{cccccccccccc} 6&-2&-2&-2&-3&1&1&1&-3&1&1&1\\  0&4&-2&-2&0&-2&1&1&0&-2&1&1\\  0&0&2&-2&0&0&-1&1&0&0&-1&1\\
		0&0&0&0&3&-1&-1&-1&-3&1&1&1\\  0&0&0&0&0&2&-1&-1&0&-2&1&1 \\  0&0&0&0&0&0&1&-1&0&0&-1&1\end{array}\right)
	\end{align*}
	The F statistic is:
	\begin{align*}
		F &= \frac{SSC/v_{AB}}{SSE/v_E}= \frac{({\bf C}\hat{{\bm\mu}})'[{\bf C}({\bf W}'{\bf W})^{-1}{\bf C}']^{-1}{\bf C}\hat{{\bm\mu}}/v_{AB}}{SSE/v_E}
	\end{align*}
	with 
	\begin{align*}
		v_{AB} &= (a - 1)\times (b - 1) = 2 \times 3 = 6
	\end{align*}
	Corresponding SAS code and output:
	\begin{center}
		\includegraphics[width = 12cm]{q209.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 12cm]{q210.jpg}
	\end{center}
	The p value is significant $(0.027)$ and we reject the null and conclude that there is interaction between cement and aggregate.
     \vskip 2mm
     For part $(b)$:\vskip 2mm
     The ``constrained'' cell means model here with additivity is:
     \begin{align*}
     	{\bf y} = {\bf W}{\bm\mu} + {\bm \epsilon} \text{ subject to } {\bf C}{\bf \mu} = 0
     \end{align*}
     where ${\bf C}$ is the contrast matrix for testing interaction that we got from part $(a)$.\vskip 2mm
     We can reparametrize the model using:
     \begin{align*}
          {\bf A}_{\text{new}} &= \left(\begin{array}{c} {\bf K}\\ {\bf C}\end{array}\right)
     \end{align*}
     here the first row of $K$ correspond to mulitiple of overall mean, and the reamaing rows of $K$ could include the contrasts for main effects. So we have
     \begin{align*}
     	{\bf K} &= \left(\begin{array}{c} {\bf j}'\\ {\bf A}\\ {\bf B}\end{array}\right) = \left(\begin{array}{cccccccccccc} 1&1&1&1&1&1&1&1&1&1&1&1\\ 2&2&2&2&-1&-1&-1&-1&-1&-1&-1&-1\\ 0 &0&0&0&1&1&1&1&-1&-1&-1&-1 \\ 3&-1&-1&-1&3&-1&-1&-1&3&-1&-1&-1\\ 0 &2&-1&-1&0&2&-1&-1&0&2&-1&-1\\ 0&0&1&-1&0&0&1&-1&0&0&1&-1\end{array}\right)
     \end{align*}
     and 
     \begin{align*}
     	{\bf A}_{\text{new}} &= \left(\begin{array}{c} {\bf K}\\ {\bf C}\end{array}\right) = \left(\begin{array}{cccccccccccc} 1&1&1&1&1&1&1&1&1&1&1&1\\ 2&2&2&2&-1&-1&-1&-1&-1&-1&-1&-1\\ 0 &0&0&0&1&1&1&1&-1&-1&-1&-1 \\ 3&-1&-1&-1&3&-1&-1&-1&3&-1&-1&-1\\ 0 &2&-1&-1&0&2&-1&-1&0&2&-1&-1\\ 0&0&1&-1&0&0&1&-1&0&0&1&-1 \\6&-2&-2&-2&-3&1&1&1&-3&1&1&1\\  0&4&-2&-2&0&-2&1&1&0&-2&1&1\\  0&0&2&-2&0&0&-1&1&0&0&-1&1\\
		0&0&0&0&3&-1&-1&-1&-3&1&1&1\\  0&0&0&0&0&2&-1&-1&0&-2&1&1 \\  0&0&0&0&0&0&1&-1&0&0&-1&1\end{array}\right)
     \end{align*}
     thanks to the previous work in part $(a)$, all the rows of ${\bf A}_{\text{new}}$ are mutually orthogonal and the rank of ${\bf A}_{\text{new}}$ is full rank (rank 12).\vskip 2mm
     So we can reparametrize the model now with
     \begin{align*}
     	{\bf y} &= {\bf W}{\bf A}_{\text{new}}^{-1}{\bf A}_{\text{new}}{\bm \mu} + {\bm \epsilon}  \text{ subject to } {\bf C}{\bm\mu} = {\bf 0}\\
     	&= {\bf Z}{\bm \delta} + {\bm\epsilon}  \text{ subject to } {\bf C}{\bm\mu}= {\bf 0}
     \end{align*}
     where ${\bf Z} = {\bf W}{\bf A}_{\text{new}}^{-1}$ and ${\bm\delta} = {\bf A}_{\text{new}}{\bm\mu}$.\vskip 2mm
%     We partition ${\bm\delta}$ into 
%     \begin{align*}
%     		{\bm\delta} &= {\bf A}_{\text{new}}{\bm\mu} = \left(\begin{array}{c} {\bf K}{\bm\mu}\\{\bf C}{\bm\mu} \end{array}\right)= \left(\begin{array}{c} {\bm \delta}_1\\ {\bm \delta}_2\end{array}\right)
%     \end{align*}
	We follow the notation from the textbook so the hypothesis for testing the main effect of cement (factor A) is:
	\begin{align*}
		H_0: {\bf A}\hat{{\bm \mu}}_c= {\bf 0}
	\end{align*}
	with F statistic:
	\begin{align*}
		F = \frac{({\bf A}\hat{{\bm \mu}}_c)'[{\bf A}{\bf K}^{\ast}({\bf Z}_1'{\bf Z}_1)^{-1}({\bf K}^{\ast })'{\bf A}']^{-1}{\bf A}\hat{{\bm \mu}}_c/v_A}{SSE_c/v_{E_c}}
	\end{align*}
	Similarly we have the hypothesis for testing the main effect of aggregate (factor B) under constrained model:
	\begin{align*}
		H_0: {\bf B}\hat{{\bm \mu}}_c= {\bf 0}
	\end{align*}
	with F statistic:
	\begin{align*}
		F = \frac{({\bf B}\hat{{\bm \mu}}_c)'[{\bf B}{\bf K}^{\ast}({\bf Z}_1'{\bf Z}_1)^{-1}({\bf K}^{\ast })'{\bf B}']^{-1}{\bf B}\hat{{\bm \mu}}_c/v_B}{SSE_c/v_{E_c}}
	\end{align*}
	The following SAS code compute the necessary quantities needed in order to get F statistics, including ${\bf K}, {\bf K}^{\ast}, {\bf A}_{\text{new}}, {\bf Z}, {\bf Z}_1, \hat{{\bm\mu}}_c$ and $SSE_c$. Specifically, 
	\begin{align*}
		{\bf K}^{\ast} = {\bf K}'({\bf K}{\bf K}')^{-1}
	\end{align*}
	and ${\bf Z}_1$ is the submatrix of ${\bf Z}$ composed of the first $6$ columns. With ${\bf Z}_1$ and ${\bf K}^{\ast}$ we can compute
	\begin{align*}
		\hat{{\bm \mu}}_c &= {\bf K}^{\ast}({\bf Z}_1'{\bf Z}_1)^{-1}{\bf Z}'_1{\bf y}
	\end{align*}
	Finally, $v_{E_c} = v_E + 6$ since ${\bf C}$ is of rank $6$.\vskip 2mm
	The SAS code is given as following:
	\begin{center}
		\includegraphics[width = 14cm]{q211.jpg}
	\end{center}
	In the output we show $SSE_c$, two F statistics for testing the main effects, and their corresponding p values:
	\begin{center}
		\includegraphics[width = 10cm]{q212.jpg}
	\end{center}
	The F statistic for testing the main effect of cement gives value $1.89$ with p value $0.17$, which is not significant and we conclude that under the constrained additive model, there is {\bf No} main effect from cement. The F statistic for testing the main effect of aggregate gives value $13.468 $ with p value $0.0000146$, which is significant, so we conclude that under the constrained model there is a main effect coming from aggregate.\vskip 2mm
	For part $(c)$:\vskip 2mm
	Suppose the combination of type $3$ cement and type B aggregate is not available, we are missing information for $\mu_{32}$. To help us analyze and find the right contrasts for our hypothesis, we look at the folloing table:
	\begin{center}
		\includegraphics[width = 12cm]{q213.jpg}
	\end{center}
	Our parameter is now
	\begin{align*}
		{\bm \mu} &= (\mu_{11}, \mu_{12}, \mu_{13}, \mu_{14}, \mu_{21}, \mu_{22}, \mu_{23}, \mu_{24}, \mu_{31}, \mu_{33}, \mu_{34})'
	\end{align*}
	Notice the length is $11$ now instead of $12$.\vskip 2mm
	We make hypothesis for the main effect from cement:
	\begin{align*}
		H_0: \left\{\begin{array}{l} 2(\mu_{11} + \mu_{13} + \mu_{14}) = (\mu_{21} + \mu_{23} + \mu_{24}) + (\mu_{31} + \mu_{33} + \mu_{34})\\ \mu_{21} + \mu_{23} + \mu_{24} = \mu_{31} + \mu_{33} + \mu_{34}\end{array}\right.
	\end{align*}
	the contrast matrix is:
	\begin{align*}
		A = \left(\begin{array}{ccccccccccc} 2&0&2&2&-1&0&-1&-1&-1&-1&-1\\ 0&0&0&0&1&0&1&1&-1&-1&-1 \end{array}\right)_{2 \times 11}
	\end{align*}
	we also make hypothesis for the main effect from aggregate:
	\begin{align*}
		H_0: \left\{\begin{array}{l} 3(\mu_{11} + \mu_{21}) = (\mu_{12} + \mu_{22}) + (\mu_{13} + \mu_{23}) + (\mu_{14} + \mu_{24}) \\ 2(\mu_{12} + \mu_{22}) = (\mu_{13} + \mu_{23}) + (\mu_{14} + \mu_{24})\\ \mu_{13} + \mu_{23}=  \mu_{14} + \mu_{24}\end{array}\right.
	\end{align*}
	the contrast matrix is:
	\begin{align*}
		B = \left(\begin{array}{ccccccccccc} 3&-1&-1&-1&3&-1&-1&-1&0&0&0\\ 0&2&-1&-1&0&2&-1&-1&0&0&0\\ 0&0&1&-1&0&0&1&-1&0&0&0\end{array}\right)_{3 \times 11}
	\end{align*}
	Finally we make hypothesis for interaction as:
	\begin{align*}
		H_0: \left\{\begin{array}{l} \mu_{11} - \mu_{21} = \mu_{12} - \mu_{22}\\ \mu_{12} - \mu_{22} = \mu_{13} - \mu_{23}\\ \mu_{12} - \mu_{22} = \mu_{14} - \mu_{24}\\ \mu_{11} - \mu_{31} = \mu_{13} - \mu_{33}\\ \mu_{11} - \mu_{31} = \mu_{14} - \mu_{34}\end{array}\right.
	\end{align*}
	The corresponding contrast matrix is:
	\begin{align*}
		C = \left(\begin{array}{ccccccccccc}1&-1&0&0&-1&1&0&0&0&0&0\\ 0&1&-1&0&0&-1&1&0&0&0&0\\ 0&1&0&-1&0&-1&0&1&0&0&0\\ 1&0&-1&0&0&0&0&0&-1&1&0\\ 1&0&0&-1&0&0&0&0&-1&0&1\end{array}\right)_{5 \times 11}
	\end{align*}
	We use proc glm as in the bakery study example:
	\begin{center}
		\includegraphics[width = 12cm]{q214.jpg}
	\end{center}
	The output for the contrast hypothesis test is:
	\begin{center}
		\includegraphics[width = 14cm]{q215.jpg}
	\end{center}
	From the output we see the main effect from cement and aggregate are both significant, however no enough evidence support the existence of interaction (fail to reject with high p-value of $0.77$).\vskip 2mm
	We also check the type IV sum of square with default glm output:
	\begin{center}
		\includegraphics[width = 12cm]{q216.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 12cm]{q217.jpg}
	\end{center}
	comparing with the sum of square from contrasts, we got the same sum of square for cement main effect and interaction, but different sum of square for the aggregate main effect.\vskip 2mm
	For part $(d)$:\vskip 2mm
	With the same assumption as $(c)$, to test for interaction:\vskip 2mm
	First consider using Full-Reduced model approach:\vskip 2mm
	The full model is the unconstrained model:
	\begin{align*}
		{\bf y} = {\bf W}{\bm\mu} + {\bm\epsilon} = ({\bf W}_1, {\bf O})\left(\begin{array}{c} {\bm \mu}_{o}\\ {\bm\mu}_{e}\end{array}\right) + {\bm\epsilon}
	\end{align*}
	with 
	\begin{align*}
		SSE_u &= {\bf y}'[{\bf I} - {\bf W}({\bf W}'{\bf W})^-{\bf W}']{\bf y}
	\end{align*}
	of degree of freedom $(n - ab + m)$.\vskip 2mm
	On the other hand there is reduced model that is additive subject to a constraint:
	\begin{align*}
	{\bf y} = {\bf W}{\bf A}_{\text{repar}}^{-1}{\bf A}_{\text{repar}}{\bm\mu} + {\bm\epsilon} \text{ subject to } {\bf G}{\bm \mu} = 0
	\end{align*}
	Here we use the notation ${\bf A}_{\text{repar}}$ to indicate this is the matrix for reparametrization, and later we will use ${\bf A}$, ${\bf B}$ and ${\bf C}$ to denote the contrast matrix for main effects and interaction.\vskip 2mm
	We have:
	\begin{align*}
		{\bf A}_{\text{repar}}  = \left(\begin{array}{c} {\bf K}\\ {\bf G}\end{array}\right)
	\end{align*}
	In our case, we have:
	\begin{align*}
		{\bf K} &= \left(\begin{array}{c} {\bf j}'\\ {\bf A}\\ {\bf B}\end{array}\right)\\
		{\bf G} &= {\bf C}
	\end{align*}
	where ${\bf A}$ is the contrast matrix for main effect from cement, ${\bf B}$ is the contrast matrix for the main effect from aggregate, and ${\bf C}$ is the contrast matrix for interaction.\vskip 2mm
	We rearrange ${\bf W}$ so the empty cell appears in the last column, and we do the same rearrangement for response ${\bf y}$.\vskip 2mm
	So the parameters are reordered as:
	\begin{align*}
		{\bm \mu} &= (\mu_{11}, \mu_{12}, \mu_{13}, \mu_{14}, \mu_{21}, \mu_{22}, \mu_{23}, \mu_{24}, \mu_{31}, \mu_{33}, \mu_{34}, \mu_{32})
	\end{align*}
	Our hypothesis stays the same for each part so does the contrast matrix. (we are doing full-reduced model approach here so our contrast would be proposed as if there is no empty sell). We did make a re-arrangement of the parameter so the contrast matrices would be slighty different than before.
	For main effect of cement, we still have:
	\begin{align*}
		H_0:  \left \{\begin{array}{l}2(\mu_{11} + \mu_{12} + \mu_{13} + \mu_{14}) = (\mu_{21} + \mu_{22} + \mu_{23} + \mu_{24}) + (\mu_{31} + \mu_{32} + \mu_{33} + \mu_{34}) \\ \mu_{21} + \mu_{22} + \mu_{23} + \mu_{24} = \mu_{31} + \mu_{32} + \mu_{33} + \mu_{34} \end{array}\right.
	\end{align*}
	But the contrast matrix is now:
	\begin{align*}
		{\bf A} &= \left(\begin{array}{cccccccccccc} 2&2&2&2&-1&-1&-1&-1&-1&-1&-1&-1\\ 0 &0&0&0&1&1&1&1&-1&-1&-1&-1\end{array}\right)
	\end{align*}
	For main effect of aggregate, we have:
	\begin{align*}
		H_0: \left\{\begin{array}{l} 3(\mu_{11} + \mu_{21} + \mu_{31}) = (\mu_{12} + \mu_{22} + \mu_{32}) + (\mu_{13} + \mu_{23} + \mu_{33}) + (\mu_{14} + \mu_{24} + \mu_{34})\\ 2(\mu_{12} + \mu_{22} + \mu_{32}) = (\mu_{13} + \mu_{23} + \mu_{33}) + (\mu_{14} + \mu_{24} + \mu_{34})\\ \mu_{13} + \mu_{23} + \mu_{33} = \mu_{14} + \mu_{24} + \mu_{34}\end{array}\right.
	\end{align*}
	the contrast matrix is now:
	\begin{align*}
		{\bf B} &= \left(\begin{array}{cccccccccccc} 3&-1&-1&-1&3&-1&-1&-1&3&-1&-1&-1\\ 0 &2&-1&-1&0&2&-1&-1&0&-1&-1&2\\ 0&0&1&-1&0&0&1&-1&0&1&-1&0\end{array}\right)
	\end{align*}
	and finally for the interaction, we use hadamad product to get the contrst matrix as:
	\begin{align*}
		{\bf C} = \left(\begin{array}{cccccccccccc} 6&-2&-2&-2&-3&1&1&1&-3&1&1&1\\  0&4&-2&-2&0&-2&1&1&0&1&1&-2\\  0&0&2&-2&0&0&-1&1&0&-1&1&0\\
		0&0&0&0&3&-1&-1&-1&-3&1&1&1\\  0&0&0&0&0&2&-1&-1&0&1&1&-2 \\  0&0&0&0&0&0&1&-1&0&-1&1&0\end{array}\right)
	\end{align*}
	We can then get ${\bf K}$ and compute
	\begin{align*}
			{\bf K}^{\ast} = {\bf K}'({\bf K}{\bf K}')^{-1}
	\end{align*}
	and then we have
	\begin{align*}
		{\bf Z}_1 &= {\bf W}{\bf K}^{\ast}
	\end{align*}
	and is able to get
	\begin{align*}
		SSE_a &= {\bf y}'[{\bf I} - {\bf Z}_1({\bf Z}_1'{\bf Z}_1)^{-1}{\bf Z}_1']{\bf y}
	\end{align*}
	so we can get the testing statsitic for interaction as
	\begin{align*}
		F = \frac{(SSE_a - SSE_u)/[3 \times 2 - 1]}{SSE_u/(32 - 12 + 1)} \sim F(5, 21) \text{ under the null}
	\end{align*}
	The SAS code are as following:
	\begin{center}
		\includegraphics[width = 14cm]{q224.jpg}
	\end{center}
	I got the following output:
	\begin{center}
		\includegraphics[width = 10cm]{q225.jpg}
	\end{center}
	The p value is highly insignificant, and we fail to reject the null and conclude that there is not enough evidence to support the existence of interaction.\vskip 2mm
	Now consider the side condition approach:
	\begin{align*}
		\gamma_{32}^{\ast} &= \mu_{32} - \bar{\mu}_{3\cdot} - \bar{\mu}_{\cdot 2} + \bar{\mu}_{\cdot\cdot} = 0\\
	\end{align*}
	We then we have:
	\begin{align*}
		&\Longrightarrow \mu_{32} - \frac{1}{4}(\mu_{31} + \mu_{32} + \mu_{33} + \mu_{34}) - \frac{1}{3}(\mu_{12} + \mu_{22} + \mu_{32}) + \frac{1}{12}\sum_{i = 1}^3
\sum_{j = 1}^4\mu_{ij} = 0	\\
&\Longrightarrow 12\mu_{32} - 3\mu_{3\cdot} - 4\mu_{\cdot 2} + \mu_{\cdot\cdot} = 0 \end{align*}
this simplies to
\begin{align*}
	(1, -3, 1, 1, 1, -3, 1, 1, -2, -2, -2, 6){\bm\mu} = 0
\end{align*}
with
\begin{align*}
	{\bm\mu} &= (\mu_{11}, \mu_{12}, \mu_{13}, \mu_{14}, \mu_{21}, \mu_{22}, \mu_{23}, \mu_{24}, \mu_{31}, \mu_{33}, \mu_{34}, \mu_{32})
\end{align*}
(don't forget that the last column of ${\bf W}$ is $0$ and $\mu_{32}$ is the last parameter now). \vskip 2mm
So 
\begin{align*}
	{\bf T} = (1, -3, 1, 1, 1, -3, 1, 1, -2, -2, -2, 6)
\end{align*} 
is our $m \times ab$ (m = 1, a = 3, b = 4) matrix with the only row that corresponds to $\mu_{32} -  \bar{\mu}_{3\cdot} - \bar{\mu}_{\cdot 2} + \bar{\mu}_{\cdot\cdot }$ for $1$ empty cell. We can get
\begin{align*}
	\hat{{\bm \mu}} &= ({\bf W}'{\bf W} + {\bf T}'{\bf T})^{-1}{\bf W}'{\bf y}
\end{align*}
and the the F statistic for testing interaction would be
\begin{align*}
	F &= \frac{({\bf C}\hat{{\bm \mu}})'\{{\bf C}[cov(\hat{{\bm \mu}})/\sigma^2]{\bf C}'\}^-({\bf C}\hat{\bm\mu})/[2 \times 3  - 1]}{SSE/(32 - 12 + 1)} \sim F(5, 21) \text{ under null}
\end{align*}
The following is the SAS code:
\begin{center}
	\includegraphics[width = 14cm]{q226.jpg}
\end{center}
\begin{center}
	\includegraphics[width = 8cm]{q227.jpg}
\end{center}
As we can see it gives the same p value as in the full-reduced models approach, and we fail to reject the null hypothesis and conclude that there is no enough evidence showing the interaction between aggregate and cement.\vskip 2mm
We also notice that the SSE in the side condition approach is the same as the $SSE_u$ in the full-reduced model approach.\vskip 2mm
	Thus completed part $(d)$.\vskip 2mm
	For part $(e)$:\vskip 2mm
	Consider the data with only one factor aggregator, the cell mean coding gives the model as
	\begin{align*}
		y_{ij} = \mu_i+ \epsilon_{ij}
	\end{align*}
	here $i = 1, 2, 3, 4$ and $j = 1, 2, \ldots, n_i$.\vskip 2mm
	We consider this is a linear model with matrix form
	\begin{align*}
		{\bf y} = {\bf W}{\bm\mu} + {\bm\epsilon}
	\end{align*}
	To test on main effect, we have
	\begin{align*}
		H_0: \mu_{1} = \mu_2 = \mu_3 = \mu_4
	\end{align*}
	and the test statistic is 
	\begin{align*}
		F = \frac{SSB/(k - 1)}{SSE/(n - k)} = \frac{(\hat{{\bm\mu}}'{\bf W}{\bf y} - N\bar{y}^2_{\cdot\cdot})/(4 - 1)}{({\bf y}'{\bf y} - \hat{{\bm\mu}}'{\bf W}{\bf y})/(33 - 4)} \sim F(3, 29) \text{ under }H_0
	\end{align*}
	We have the following code and output:
	\begin{center}
		\includegraphics[width = 13cm]{q218.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 8cm]{q219.jpg}
	\end{center}
	The p-value here is significant so we reject the null and conclude there is a main effect from the aggregate.\vskip 2mm
	For reference cell coding, the model is:
	\begin{align*}
		y_{1j} &= \mu + \epsilon_{1j}\\
		y_{2j} &= \mu + \alpha_2 + \epsilon_{2j}\\
		&\ \vdots\\
		y_{kj} &= \mu + \alpha_k + \epsilon_{kj}
	\end{align*}
	We will have a different design matrix than the cell means coding. The matrix form of the model now is
	\begin{align*}
		{\bf y} &= {\bf X}{\bm\beta} + {\bm\epsilon}
	\end{align*}
	The SAS code is the following:
	\begin{center}
		\includegraphics[width = 13cm]{q220.jpg}
	\end{center}
	The output is the same as the cell means model:
	\begin{center}
		\includegraphics[width = 8cm]{q221.jpg}
	\end{center}
	and we conclude there is a main effect from aggregate.\vskip 2mm
	Now for effect cell coding:
	\begin{align*}
		y_{1j} &= \mu - \alpha_2 - \ldots - \alpha_k + \epsilon_{1j}\\
		y_{2j} &= \mu + \alpha_2 + \epsilon_{2j}\\
		&\vdots \\
		y_{kj} &= \mu + \alpha_k + \epsilon_{kj}
	\end{align*}
	The SAS code is the following:
	\begin{center}
		\includegraphics[width = 13cm]{q222.jpg}
	\end{center}
	The output is the same as the cell means coding and reference cell coding:
	\begin{center}
		\includegraphics[width = 8cm]{q223.jpg}
	\end{center}
	These results are not surprising, since all these different codings are essentially reparametrization of each other and they give equivalent models, so $SSR$ and $SSE$ are invariant under these different models and we should have the same F statistic for making the inference on main effect.
\end{sol}



Question $3$.
\begin{sol}
	For part $(i)$:\vskip 2mm
	We have the following data:
	\begin{center}
		\includegraphics[width = 10cm]{q301.jpg}
	\end{center}
	Our linear regression model for $y_1$ is:
	\begin{align*}
		y_1 &= \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon
	\end{align*}
	The following SAS code create the data set and we print out design matrix ${\bf X}$ and response vector $y_1$:
	\begin{center}
		\includegraphics[width = 12cm]{q302.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 8cm]{q303.jpg}
	\end{center}
	To answer question $7.54$:\vskip 2mm
	For part $(a)$:\vskip 2mm
	we first check that the design matrix is full rank (rank 4):
	\begin{center}
		\includegraphics[width = 6cm]{q304.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 6cm]{q305.jpg}
	\end{center}
	We then have:
	\begin{align*}
		\hat{{\bm \beta}} &= \Big({\bf X}'{\bf X}\Big)^{-1}{\bf X}'{\bf y}_1\\
		s^2 &= \frac{SSE}{n - k - 1} = \frac{SSE}{19 - 3 -1} = \frac{SSE}{4} = {\bf y}_1'\Big(I - {\bf X}({\bf X}'{\bf X})^{-1}{\bf X}'\Big){\bf y}_1/4
	\end{align*}
	The following SAS code compute $\hat{\beta}$ and $s^2$:
	\begin{center}
		\includegraphics[width = 10cm]{q306.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 6cm]{q307.jpg}
	\end{center}
	So we have:
	\begin{align*}
		\hat{{\bm \beta}} &= (332.11098, -1.545961, -1.424559, -2.237366)'\\
		s^2 &= 5.3449026
	\end{align*}
	For part $(b)$:\vskip 2mm
	Since we have:
	\begin{align*}
		cov({\bm \beta}) &= \sigma^2\Big({\bf X}'{\bf X}\Big)^{-1}
	\end{align*}
	Thus an estimate would be:
	\begin{align*}
		cov(\hat{{\bm \beta}}) &= \hat{\sigma}^2\Big({\bf X}'{\bf X}\Big)^{-1} = s^2\Big({\bf X}'{\bf X}\Big)^{-1}
	\end{align*}
	The following SAS code provide this computation:
	\begin{center}
		\includegraphics[width = 8cm]{q308.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 8cm]{q309.jpg}
	\end{center}
	the output above is $cov(\hat{{\bm \beta}})$.\vskip 2mm
	For part $(c)$:\vskip 2mm
	We have:
	\begin{align*}
		R^2 &=\frac{SSR}{SSE} =  \frac{\hat{{\bm \beta}}'{\bf X}'{\bf y} - n\bar{y}^2}{SST}\\
		R^2_a &= \frac{(n - 1)R^2 - k}{n - k  - 1}
	\end{align*}
	The following SAS code provide this computation:
	\begin{center}
		\includegraphics[width = 8cm]{q310.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 5cm]{q311.jpg}
	\end{center}
	So we got:
	\begin{align*}
		R^2 &= 0.9551434\\
		R^2_{adj} &= 0.9461721
	\end{align*}
	For part $(d)$ and part $(e)$:\vskip 2mm
	We consider second order model:
	\begin{align*}
		y_1 &= \beta_0 + \beta_1 x_1 + \beta_2x_2 + \beta_3x_3 + \beta_4x_1^2 + \beta_5x_2^2
		+ \beta_6x_3^2+ \beta_7x_1x_2 + \beta_8x_1x_3 + \beta_9x_2x_3 + \epsilon
	\end{align*}
	The following SAS create design matrix for this model and compute $\hat{\beta}, s^2, R^2$ and $R^2_a$.
	\begin{center}
		\includegraphics[width = 12cm]{q312.jpg}
	\end{center}
	we have also checked that the design matrix for the second order model is also with full rank $10$.
	\begin{center}
		\includegraphics[width = 10cm]{q313.jpg}
	\end{center}
	So we have found that:
	\begin{align*}
		\hat{{\bm \beta}} &= \left[\begin{array}{c}964.92906 \\ -7.442128\\ -11.5077\\ -2.140127\\0.0124571 \\ 0.0332188\\ -0.294014\\ 0.053507\\ 0.03804\\ -0.101633\end{array}\right]
	\end{align*}
	and 
	\begin{align*}
		s^2 = MSE = 5.1342507
	\end{align*}
	we have also foud
	\begin{align*}
		R^2 &= 0.9741468\\
		R^2_{adj} &= 0.9482936
	\end{align*}
	Thus finished solving part $(a)$(ie. Exercise 7.54).\vskip 2mm
	For part $(b)$:\vskip 2mm
	If we assume the second order model is the correct full model, then when the second order terms are ignored, the underfitted first order reduced model will cause the bias on the estimate of coefficients $\hat{{\bm \beta}}$, the predicted values $\hat{{\bf y}}$ and the estimate of variance $s^2$. It has been shown also that $s^2$ for the reduced model will be biased upward.\vskip 2mm
	For part $(c)$:\vskip 2mm
	We use the second order model to conduct the residual analysis here.\vskip 2mm
	We compute regular residuals $\hat{e}_i$, studentized residuals $r_i$, studentized external residuals $t_i$ and deleted residuals $\hat{e}_{(i)}$ for later use. The code is as following:
	\begin{center}
		\includegraphics[width = 10cm]{q314.jpg}
	\end{center}
	To locate outliers, we make a scatter plot of studentized residuals against fitted value, and deleted residuals against fitted value, as well as deleted residual against ordinary residuals:
	\begin{center}
		\includegraphics[width = 10cm]{q315.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 7cm]{q316.jpg}\includegraphics[width = 7cm]{q317.jpg}
	\includegraphics[width = 7cm]{q318.jpg}
	\end{center}
	We can see that both residual plots against fitted values display similar patterns, although some potential outliers behave differently. We marked the outlier candidates with red circles. The deleted residual vs regular residual shows a straightline pattern, with one point deviated far away, which suggested a potential influential observation. We will do further analysis in the following.\vskip 2mm
	To find influential observations, we compute the following:
	\begin{enumerate}
		\item studentized ($r_i$), studentized external ($t_i$) and deleted ($\hat{e}_{(i)}$) residuals, the code of which is shown above.
		\item PRESS: prediction sum of square
		\item Cooks distance
	\end{enumerate}
	Our code is as following:
	also, as suggested by Hoaglin and Welsch(1978), the high leverage point is
	\begin{align*}
		\frac{2k + 1}{n} = \frac{2 \times (9 + 1)}{19} = 1.052632
	\end{align*}
	We print out a table similar to Table $9.1$ as the example from the book:
	\begin{center}
		\includegraphics[width = 14cm]{q320.jpg}
	\end{center}
	The observation number here are manually added just to make it easier to point out which observation we are talking about. But it is not the real observation index since it is not given by the data.\vskip 2mm
	There is no observation that has a leverage higher than the suggested high leverage. Observation $1$, $4$, $11$, and $14$ have relatively higher leverage.From the leverage aspect, these points can be potentially influential to the model.\vskip 2mm
	If we look at Cook's distance, observation $1$ has a much larger value than the rest, implying that it might be most influential than the other observations. Observation $12$ also has a relatively larger cooks' distance than the others.\vskip 2mm
	In terms of residuals, observation $12$ is the only one with studentized and studentized external residuals with magnitude larger than $2$.\vskip 2mm
	So to summarize, we conclude that the two most influential observations are observation $1$ and $12$.\vskip 2mm
	Our PRESS value is $219.75$, if we want to compare between models with different observations, the one with smaller PRESS value will be more preferrable.\vskip 2mm
	For  part $(iv)$:\vskip 2mm
	for any particular coefficient $\beta_j$, we know that
	\begin{align*}
		P\Big[-t_{\alpha/2, n - k - 1} \leq \frac{\hat{\beta}_j - \beta_j}{s\sqrt{g_{jj}}} \leq t_{\alpha/2, n - k - 1}\Big] = 1 - \alpha.
	\end{align*}
	which gives the $100(1 - \alpha)\%$ confidence interval for $\beta_j$ as:
	\begin{align*}
		\hat{\beta}_j \pm t_{\alpha/2, n -  k- 1}s\sqrt{g_{jj}}
	\end{align*}
	Here $g_{jj}$ is the jth diagonal element of $({\bf X}'{\bf X})^{-1}$.\vskip 2mm
	The following SAS code compute $95\%$ confidence intervals for $\beta_1$ to $\beta_9$
	\begin{center}
		\includegraphics[width = 12cm]{q321.jpg}
	\end{center}
	The output is:
	\begin{center}
		\includegraphics[width = 12cm]{q322.jpg}
	\end{center}
	reorganize the answer, we got the $95\%$ confidence intervals for each $\beta_j$ as:
	\begin{align*}
		&\ \beta_1: (-23,46535, 8.5810898)\hskip 1cm \beta_2:  (-29.79275, 6.7773418) \hskip 1cm \beta_3: (-36.85452, 32.574268)\\
		&\ \beta_4: (-0.03268, 0.0575947)\hskip 1cm \beta_5: (-0.081384, 0.147822)\hskip 1cm 
		\beta_6: (-0.802502, 0.2144737)\\
		&\  \beta_7: (-0.027781, 0.1347949)\hskip 1cm \beta_8: (-0.186424, 0.2625041) \hskip 1cm \beta_9: (-0.443609, 0.2403428)
	\end{align*}
	Now for confidence interval of $\sigma^2$, we have:
	\begin{align*}
		P\Big[\chi^2_{1 - \alpha/2, n - k - 1}\leq \frac{(n - k - 1)s^2}{\sigma^2} \leq \chi^2_{\alpha/2, n - k - 1}\Big] = 1 - \alpha
	\end{align*}
	which gives the $100(1 - \alpha)\%$ confidence interval for $\sigma^2$ as:
	\begin{align*}
		\frac{(n - k - 1)s^2}{\chi^2_{\alpha/2, n - k - 1}} \leq \sigma^2 \leq \frac{(n -  k - 1)s^2}{\chi^2_{1 - \alpha/2, n - k - 1}}
	\end{align*}
	The sas code and output are as following:
	\begin{center}
		\includegraphics[width = 8cm]{q323.jpg}
	\end{center}
	\begin{center}
		\includegraphics[width = 4cm]{q324.jpg}
	\end{center}
	So the $95\%$ confidence interval for $\sigma^2$ is $(2.4291027, 17.1117)$.\vskip 2mm
	Thus finished the solution of Question $3$.
\end{sol}













\end{document}
